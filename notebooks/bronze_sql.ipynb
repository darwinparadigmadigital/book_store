{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec041d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebooks/includes/Copy-Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "env = dbutils.widgets.get(\"environment\")  # o la que definas\n",
    "dataset_bookstore = spark.conf.get(\"dataset.bookstore\")\n",
    "\n",
    "# Customers (JSON)\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE dev_mayoral.bronze_uc_{env}.customers AS\n",
    "SELECT * \n",
    "FROM json.`{dataset_bookstore}/customers-json`\n",
    "\"\"\")\n",
    "\n",
    "# Orders (Parquet)\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE dev_mayoral.bronze_uc_{env}.orders AS\n",
    "SELECT * \n",
    "FROM parquet.`{dataset_bookstore}/orders`\n",
    "\"\"\")\n",
    "\n",
    "# Books unparsed (CSV)\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE dev_mayoral.bronze_uc_{env}.books_unparsed AS\n",
    "SELECT * \n",
    "FROM csv.`{dataset_bookstore}/books-csv`\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vista temporal en Python\n",
    "books_tmp_vw = spark.read.csv(\n",
    "    f\"{dataset_bookstore}/books-csv/export_*.csv\",\n",
    "    header=True,\n",
    "    sep=\";\",\n",
    "    schema=\"book_id STRING, title STRING, author STRING, category STRING, price DOUBLE\"\n",
    ")\n",
    "books_tmp_vw.createOrReplaceTempView(\"books_tmp_vw\")\n",
    "\n",
    "# Crear tabla final\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE dev_mayoral.bronze_uc_{env}.books AS\n",
    "SELECT * \n",
    "FROM books_tmp_vw\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, concat, split, rand, element_at, array\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# get_url UDF\n",
    "def get_url(email):\n",
    "    return f\"https://www.{email.split('@')[1]}\"\n",
    "\n",
    "spark.udf.register(f\"get_url_{env}\", get_url, StringType())\n",
    "\n",
    "# get_country UDF\n",
    "countries = [\"EC\", \"IT\", \"TR\", \"ES\", \"CO\", \"CH\", \"NL\", \"IN\", \"BR\"]\n",
    "def get_country():\n",
    "    import random\n",
    "    return random.choice(countries)\n",
    "\n",
    "spark.udf.register(f\"get_country_{env}\", get_country, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc55d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import random\n",
    "\n",
    "# -------------------------------\n",
    "# Definir env y dataset_bookstore\n",
    "# -------------------------------\n",
    "env = dbutils.widgets.get(\"environment\")  # Por ejemplo 'dev' o 'prod'\n",
    "dataset_bookstore = spark.conf.get(\"dataset.bookstore\")\n",
    "\n",
    "# -------------------------------\n",
    "# UDF: get_url (seguro para valores nulos)\n",
    "# -------------------------------\n",
    "def get_url(email):\n",
    "    if email is None:\n",
    "        return None\n",
    "    return f\"https://www.{email.split('@')[1]}\"\n",
    "\n",
    "spark.udf.register(f\"get_url_{env}\", get_url, StringType())\n",
    "\n",
    "# -------------------------------\n",
    "# UDF: get_country (aleatorio)\n",
    "# -------------------------------\n",
    "countries = [\"EC\", \"IT\", \"TR\", \"ES\", \"CO\", \"CH\", \"NL\", \"IN\", \"BR\"]\n",
    "\n",
    "def get_country():\n",
    "    return random.choice(countries)\n",
    "\n",
    "spark.udf.register(f\"get_country_{env}\", get_country, StringType())\n",
    "\n",
    "# -------------------------------\n",
    "# Crear/actualizar tabla customers con iso_code\n",
    "# -------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE dev_mayoral.bronze_uc_{env}.customers AS\n",
    "SELECT *, get_country_{env}() AS iso_code\n",
    "FROM dev_mayoral.bronze_uc_{env}.customers\n",
    "\"\"\")\n",
    "\n",
    "# -------------------------------\n",
    "# Seleccionar emails y dominios usando get_url\n",
    "# -------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "SELECT email, get_url_{env}(email) AS domain\n",
    "FROM dev_mayoral.bronze_uc_{env}.customers\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "INSERT OVERWRITE TABLE dev_mayoral.bronze_uc_{env}.orders\n",
    "SELECT * FROM parquet.`{dataset_bookstore}/orders`\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
